########## Rainbow DQN Hyperparameters ##########

seed: 42                           # Random seed for reproducibility
disable_cuda: false                # If true, forces training on CPU even if CUDA is available
enable_cudnn: false                # If true, enables cuDNN optimizations for CNNs

T_max: 300000                      # Maximum total training steps (iterations across all episodes)
max_episode_length: 2000           # Maximum number of environment steps in a single episode

noisy_std: 0.5                     # Initial standard deviation for noisy linear layers (used for exploration)
atoms: 51                          # Number of discrete atoms for value distribution in distributional DQN
V_min: -100.0                      # Minimum support value for distributional DQN
V_max: 100.0                       # Maximum support value for distributional DQN
multi_step: 3                      # Number of steps used in multi-step returns for better credit assignment


# Reward hyperparameters
max_reward: 1                      # Maximum clipped reward
min_reward: -30                    # Minimum clipped reward


model: None                        # Path to a pre-trained model file (if resuming or fine-tuning)
exp_name: "Exp1"                   # Experiment name (used for logging and saving results)

# Replay memory (Prioritized Experience Replay - PER)
memory_capacity: 50000             # Maximum number of transitions stored in replay memory
disable_bzip_memory: false         # If true, disables bzip2 compression for replay memory storage
priority_exponent: 0.5             # Alpha: controls how much prioritization is used (0 = uniform, 1 = full prioritization)
priority_weight: 0.4               # Beta: importance sampling weight to correct bias from prioritized replay

# Learning parameters
discount: 0.99                     # Discount factor (gamma)
target_update: 1000                # Frequency (in steps) of target network updates
learning_rate: 0.0000625           # Learning rate for Adam optimizer
adam_eps: 0.00015                  # Epsilon term in Adam optimizer for numerical stability
batch_size: 64                     # Number of samples per training batch
norm_clip: 10.0                    # Maximum gradient norm (for gradient clipping to stabilize training)
replay_frequency: 1                # Number of environment steps between network updates

# Evaluation and checkpoints
evaluation_interval: 5000          # Number of steps between evaluations
evaluation_episodes: 10            # Number of episodes per evaluation
model_checkpoint_interval: 5000    # Number of steps between saving model checkpoints
memory_checkpoint_interval: 10000  # Number of steps between saving replay memory checkpoints
learn_start: 1000                  # Minimum number of steps before training starts (to pre-fill replay memory)


